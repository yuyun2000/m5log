1、前置模型更换flash，简单测试下发现效果基本和主模型一致，但是速度明显更快；
1.1、有必要的话可以用现有数据提交到火山微调flash或者自己微调一个前置过滤模型

2、现有工作流程融入乐鑫ai，并且要不显著增加用户延迟，并且模型身份和m5chatbot相匹配

3、为现有chatbot增加实时后台，可以随时查询对话统计信息、ai对以往对话的分析结果等

4、编程类问题需要长工作流，提高自主解决问题的能力，因为编程问题一般都没有现成的代码，可以考虑引入公开的第三方项目

5、多源信息获取，比如输入网站，自动爬取网页的内容到知识库，这样对补充其他人的推文、经验贴更方便

6、mcp服务器重新整理发布，同步发布至modelscope等mcp共享社区，提高m5曝光率。