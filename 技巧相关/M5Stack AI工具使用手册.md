## 📌 工具概览

### 对外服务
- **chat.m5stack.com**
  - 功能：公司对外AI技术支持
  - 特点：已接入公司知识库，可解答产品规格、参数及编程问题

### 对内服务
> ⚠️ 注意：IP地址可能变动，访问失败请联系管理员

1. **OpenWebUI - AI对话平台**  
   地址：http://192.168.20.38:8848/

2. **AI-API分发平台**  
   地址：http://192.168.20.176:3000/

3. **高级知识库助手**  
   地址：http://192.168.20.38:16002/

---

## 🤖 OpenWebUI 使用指南

### 初次使用
1. 使用**公司邮箱**注册
2. 用户名填写**中文名或英文名**
3. 注册后**联系管理员激活账号**
![](Pasted%20image%2020251127151657.png)
### 模型选择建议

#### 📝 主流问答模型

| 使用场景 | 推荐模型 | 适用任务 |
|---------|---------|---------|
| **内容创作** | **Claude** | 方案撰写、工作汇报、日报周报<br>代码编写/修改、邮件润色 |
| **快速查询** | **GPT** | 资料查询、文字修改、标题创作<br>头脑风暴 |
| **复杂问题** | **Gemini** | 图文混合提问、多步骤逻辑<br>复杂场景分析 |

#### 🎨 专用模型

**1. 图片处理 - Banana Pro**
- 平台名称：「Google文生图模型」
- 功能：
  - 文字描述生成图片
  - 图片局部编辑（添加文字、更换背景/风格等）

**2. 视频生成 - Sora**
- 状态：测试阶段，可能不稳定
- 功能：文字或图片生成短视频
- 用途：创意内容、娱乐向制作
- 💡 提示：如遇问题请多次尝试或换时段使用

---

## 🔑  公司内部 API 分发平台使用指南

公司提供了一个统一的 LLM（大语言模型）API 平台，用来在各类工具中调用 AI（例如编程助手、对话工具等）。  
只要按照本指南完成配置，就可以在支持 OpenAI 接口的工具中使用公司内部的模型。

---

## 一、基础配置信息（一定要记住）

- **API 端点地址（Endpoint）：**  
    `http://192.168.20.176:3000/v1`
    
- **模型列表（Model ID 查询）：**  
    在浏览器中访问：  
    `http://192.168.20.176:3000/pricing`  
    即可查看当前可用的模型及其 **模型 ID**（后面配置工具时会用到）。
    

---

## 二、使用前准备

1. **注册平台账号**  
    使用公司网络，访问 API 平台地址`http://192.168.20.176:3000`，按照提示注册账号。  

2. **创建 API 密钥（Token）**
    
    - 登录 API 分发平台。
    - 进入「控制台 / 个人中心 / API 密钥」等相关页面。
    - 点击「创建密钥 / 新建 Token」。
    - 将生成的 **API 密钥** 复制并妥善保存（相当于你的账户密码，不要外传）。
3. **在工具中配置 API**
    
    - 将上述的 **端点地址**
    - 以及你自己创建的 **API 密钥**  
        填写到相应工具的配置界面中（下面以 Cherry Studio 和 Cline 为例演示）。

---

## 三、额度说明 💰

- **每月免费额度：**  
    每个账号每月默认有 **$20** 的使用额度。
    
- **额度用尽后：**
    
    - 可以联系 **刘波** 申请补充额度；
    - 或等待下个月自动重置额度。

> 提示：不同模型消耗额度的速度不同，可在 `http://192.168.20.176:3000/pricing` 页面查看模型的价格和说明，选择合适的模型使用。

---

## 四、API 是用来做什么的？

你可以简单理解为：

- **API = 公司内部 AI 的“电源插座”**  
    各种工具（对话客户端、编程助手、插件等）通过这个 “插座” 获取公司内部提供的 LLM 服务。

常见使用场景包括：

- 在各种 **GPT 类客户端** 中接入公司的模型，而不是直接用外网的 GPT。
- 在 **编程工具**（如 VS Code 的 Cline 插件）中，让 AI 帮你写代码、查问题。
- 在公司提供的 **OpenWebUI** 等客户端中选择内部模型进行对话。

下面是两个常用工具的配置示例。

---

## 五、在 Cherry Studio 中使用公司 API

### 1. 安装 Cherry Studio

1. 打开浏览器访问：  
    `https://www.cherry-ai.com/`
2. 根据页面提示下载并安装 Cherry Studio 客户端（支持桌面端）。

### 2. 添加 OpenAI 类型的服务

1. 打开 Cherry Studio 客户端。
    
2. 进入：**设置 → 模型服务 → 添加**。
    
3. 选择添加一个 **OpenAI 类型** 的 API 服务。  
    （可参考下图界面进行操作）
    
![](Pasted%20image%2020251203102516.png)

### 3. 配置 API 信息

在你刚刚创建的这个服务节点中，填写以下内容：
![](Pasted%20image%2020251203102619.png)
- **API 地址（Base URL）：**  
    `http://192.168.20.176:3000`
- **API 密钥（API Key）：**  
    填写你在公司 API 平台上创建的密钥。

填写完毕后保存。

### 4. 添加模型（Model）

1. 在该服务配置页面，点击「添加模型」按钮。
2. 在弹出的窗口中，只需要填写 **模型 ID** 即可。  
    模型 ID 可以在：  
    `http://192.168.20.176:3000/pricing` 中查看。
3. 保存后，你就可以在 Cherry Studio 的对话界面选择这个模型进行对话和使用。

---

## 六、在 VS Code 的 Cline 插件中使用公司 API

### 1. 安装 Cline 插件

1. 打开 VS Code。
    
2. 在左侧扩展（Extensions）中搜索 **“Cline”**。
    
3. 点击安装，安装完成后在侧边栏打开 Cline 界面，你会看到类似下面的界面：
    
![](Pasted%20image%2020251203102852.png)

### 2. 配置模型提供商

1. 在 Cline 界面的底部，点击 **模型提供商**（Model Provider）进行配置：
    
![](Pasted%20image%2020251203102946.png)
    
2. 选择 **“OpenAI 兼容 API（OpenAI Compatible API）”** 作为类型。
    
3. 在配置中填写：
    
    - **端点地址（Base URL / Endpoint）：**  
        `http://192.168.20.176:3000/v1`
    - **API 密钥（API Key）：**  
        填写你在公司 API 平台上申请的密钥。
    - **模型 ID（Model）：**  
        可以按需填写模型 ID。  
        推荐：
        - 综合能力较强：`claude-sonnet-4-5-20250929`
        - 简单任务、性价比高：`qwen3-coder-480b-a35b-instruct`
4. 保存配置后，Cline 就会通过公司内部的 API 调用相应的模型，你可以在 VS Code 中直接使用 AI 编程助手功能。
    

---

## 七、Copilot使用公司代理
首先安装好官方的Copilot后，默认只能使用基础的模型，并且有次数限制
搜索`OAI Compatible Provider for Copilot`并安装，然后打开`setting.json`，添加以下内容：
```json
    "oaicopilot.baseUrl": "http://192.168.20.176:3000/v1",
    "oaicopilot.models": [
        {
            "id": "claude-sonnet-4-5-20250929",
            "owned_by": "m5",
            "baseUrl": "http://192.168.20.176:3000/v1",
            "context_length": 256000,
            "max_tokens": 8192,
            "temperature": 1,
            "top_p": null,
        },
        {
            "id": "claude-opus-4-5",
            "owned_by": "m5",
            "baseUrl": "http://192.168.20.176:3000/v1",
            "context_length": 256000,
            "max_tokens": 8192,
            "temperature": 1,
            "top_p": null,
        },
        {
            "id": "gemini-3-pro-preview",
            "owned_by": "m5",
            "baseUrl": "http://192.168.20.176:3000/v1",
            "context_length": 256000,
            "max_tokens": 8192,
            "temperature": 1,
        },
        {
            "id": "qwen3-coder-480b-a35b-instruct",
            "owned_by": "m5",
            "baseUrl": "http://192.168.20.176:3000/v1",
            "context_length": 256000,
            "max_tokens": 8192,
            "temperature": 1,
        },
        {
            "id": "gpt-5.1",
            "owned_by": "m5",
            "baseUrl": "http://192.168.20.176:3000/v1",
            "context_length": 256000,
            "temperature": 1,
        }
    ]
```
(claude不能同时发送温度和top参数，gpt模型不支持max_tokens参数，其他模型类似，可以自己调整发送参数)
然后点击配置模型
![](Pasted%20image%2020251203121053.png)
![](Pasted%20image%2020251203121112.png)
输入密钥后把添加的模型都加上，这样就可以在copilot中使用公司的api进行处理，注意，此时自带的补全模型依然是copilot内置的没有被替换

---

## ❓ 技术支持

如有任何问题，请联系管理员，目前是 **云炫戊**

