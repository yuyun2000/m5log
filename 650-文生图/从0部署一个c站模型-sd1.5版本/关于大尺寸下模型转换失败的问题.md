现在测试通过的是512x512 480x320或者320x480可以正常转换，再大一些就会报错，但是模型原生分辨率都比较大，如果刻意压缩分辨率生成效果和原生偏差较大

以竖图为例，现在部署的latent_shape为1x4x60x40 对应480x320

如果放大为 1x4x160x120 （1280x960）
导出onnx
```
python export_sd_c.py --input_path ./s/darkSushiMixMix_225D.safetensors --output_path ./darksu --isize 1280x960 --prompt "1girl,black dragon,black hair,bracelet,cloud,full body,gilding\\(style\\),long skirt,lotus,mountain,shawl,solo,waves,yellow eyes"
```

预览效果：
![](test.jpg)


准备数据后开始转换
```
pulsar2 build --input darksu/unet_sim_cut.onnx --config config_unet_u16.json --output_dir output_unet_1280 --output_name unet.axmodel
```
