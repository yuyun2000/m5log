端侧如果按照原来的方式进行量化，推理耗时为0.043s
如果特征顺序不改，此时的wer由 37.13% 降为 21.56%
如果修改为正确的特征顺序，此时wer变为 21.17%
和onnx的结果（15.05%）差距还很大

## 原因1：onnx测试语种是auto，端侧使用en？
端侧也是用auto模式，指标还更差了：22.18%
所以不是这个原因


## 原因2：量化损失
![](../../file/Pasted%20image%2020250826180828.png)
所有层的相似度都是0.99 但是所有的where输出都是nan，需要看一下这层在模型里的作用
掉点很有可能是在这里
具体是在`MultiHeadedAttentionSANM`-`forward_attention`
```
min_value = -float(  
    "inf"  
)  # float(numpy.finfo(torch.tensor(0, dtype=scores.dtype).numpy().dtype).min)  
scores = scores.masked_fill(mask, min_value)
```
改成65536后，不影响原始结果输出，wer为14.83%

在额外做一个实验，改成0，也就是不进行pad，看看掉点和端侧是否一致，wer变成了17.20%
涨了这么多，并且端侧数据范围更窄，实际影响确实会更大，那么就合理了...

改成65535后，转换成axmodel，指标变成了21.05%，可以说是基本没有提升
![](Pasted%20image%2020250827094401.png)
原来那几层的相似度虽然不是nan了，还依然有很大损失，改成8190后再转出，这几层都变成了0.99+
但是发现前面别的地方还有0.8x的相似度，端侧wer为21.56%：
![](Pasted%20image%2020250827101126.png)![](Pasted%20image%2020250827101143.png)
但不是每层的这个地方都掉精度，就偏后的一些层是这样，我估计还是这个mask有关系
改成128，偏差似乎还更大了
![](Pasted%20image%2020250827104923.png)
最后改成16，pt模型精度掉为14.94%，转换axmodel，情况依旧

如果不要这里的mask，直接进行推理，pt模型精度掉为15.96%，转出axmodel的时候，发现上面那个异常的matmul和下方的几层相似度偏低的层没有消失，看来问题不在这里，但是这几层是被onnx sim修过的层，找不到原始代码对应的位置，转换一下未经过onnx sim的模型

现在已经定位到是从这个`x = torch.matmul(p_attn, value)` matmul之后精度暴跌，但是在此之前有一层：
` op_603:onnx.Matmul                  │     AxQuantizedMatMul     │ op_603:onnx.Matmul_out             │ (1, 4, 164, 164) │ FP32  │  U16   │ 0.99997 │ 16553.47852 `
不知道对应的哪一层，这一层mse很大，应该已经影响精度了




### 单条音频的输入输出特征对比
由于上面工具链找不到问题在哪，但是工具链输出的最后一层相似度却是0.99
所以现在推理一条onnx和ax结果有差异的样本，看一下模型最终输出的精度问题，还是后处理或者前处理的问题
输入的特征就不对：
```
Array1 shape: (1, 164, 560)
Array2 shape: (1, 164, 560)
==================================================
Cosine Similarity: 0.882980
MSE: 4.419757e-02
MAE: 3.603352e-02
Max Absolute Diff: 5.446561e+00
Array1 Norm: 131.734146
Array2 Norm: 131.656952
Shape: (1, 164, 560)
Comparison Type: flattened
==================================================

```
相同的音频，输入的特征相似度只有0.88
