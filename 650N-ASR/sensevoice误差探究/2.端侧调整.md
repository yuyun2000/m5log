端侧如果按照原来的方式进行量化，推理耗时为0.043s
如果特征顺序不改，此时的wer由 37.13% 降为 21.56%
如果修改为正确的特征顺序，此时wer变为 21.17%
和onnx的结果（15.05%）差距还很大

## 原因1：onnx测试语种是auto，端侧使用en？
端侧也是用auto模式，指标还更差了：22.18%
所以不是这个原因


## 原因2：量化损失
![](../../file/Pasted%20image%2020250826180828.png)
所有层的相似度都是0.99 但是所有的where输出都是nan，需要看一下这层在模型里的作用
掉点很有可能是在这里
具体是在`MultiHeadedAttentionSANM`-`forward_attention`
```
min_value = -float(  
    "inf"  
)  # float(numpy.finfo(torch.tensor(0, dtype=scores.dtype).numpy().dtype).min)  
scores = scores.masked_fill(mask, min_value)
```
改成65536后，不影响原始结果输出，wer为14.83%

在额外做一个实验，改成0，也就是不进行pad，看看掉点和端侧是否一致，wer变成了17.20%
涨了这么多，并且端侧数据范围更窄，实际影响确实会更大，那么就合理了...

改成65535后，转换成axmodel，指标变成了21.05%，可以说是基本没有提升
![](Pasted%20image%2020250827094401.png)
原来那几层的相似度虽然不是nan了，还依然有很大损失，改成8190后再转出，这几层都变成了0.99+
但是发现前面别的地方还有0.8x的相似度，端侧wer为21.56%：
![](Pasted%20image%2020250827101126.png)![](Pasted%20image%2020250827101143.png)
但不是每层的这个地方都掉精度，就偏后的一些层是这样，我估计还是这个mask有关系