端侧如果按照原来的方式进行量化，推理耗时为0.043s
如果特征顺序不改，此时的wer由 37.13% 降为 21.56%
如果修改为正确的特征顺序，此时wer变为 21.17%
和onnx的结果（15.05%）差距还很大

## 原因1：onnx测试语种是auto，端侧使用en？
端侧也是用auto模式，指标还更差了：22.18%
所以不是这个原因


## 原因2：量化损失
![](../../file/Pasted%20image%2020250826180828.png)
所有层的相似度都是0.99 但是所有的where输出都是nan，需要看一下这层在模型里的作用
掉点很有可能是在这里
具体是在`MultiHeadedAttentionSANM`-`forward_attention`
```
min_value = -float(  
    "inf"  
)  # float(numpy.finfo(torch.tensor(0, dtype=scores.dtype).numpy().dtype).min)  
scores = scores.masked_fill(mask, min_value)
```
改成65536后，不影响原始结果输出，wer为14.83%

在额外做一个实验，改成0，也就是不进行pad，看看掉点和端侧是否一致，wer变成了17.20%
涨了这么多，并且端侧数据范围更窄，实际影响确实会更大，那么就合理了...